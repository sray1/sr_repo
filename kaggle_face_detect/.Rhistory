#LC_results <- mdlp(sort_data)$Disc.data
LC_results <- chi2(mod_data)$Disc.data
library('discretization')
library('discretization')
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
#LC_results <- mdlp(sort_data)$Disc.data
LC_results <- chi2(mod_data)$Disc.data
View(LC_results)
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
#LC_results <- mdlp(sort_data)$Disc.data
LC_results <- mdlp(sort_data)
# LC data
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
LC_results <- mdlp(sort_data)$Disc.data
#LC_results <- chi2(mod_data)$Disc.data
LC_results$$Disc.data
LC_results$cutp
# LC data
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
LC_results <- mdlp(mod_data)
#LC_results <- chi2(mod_data)
LC_results$$Disc.data
LC_results$cutp
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
LC_results <- mdlp(mod_data)
#LC_results <- chi2(mod_data)
LC_results$Disc.data
LC_results$cutp
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
#LC_results <- mdlp(mod_data)
LC_results <- chi2(mod_data)
LC_results$Disc.data
LC_results$cutp
View(mod_data)
# LC data
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
#LC_results <- mdlp(mod_data)
#LC_results <- chi2(mod_data)
LC_results <- chiM(mod_data)
LC_results$Disc.data
LC_results$cutp
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
#LC_results <- mdlp(mod_data)
#LC_results <- chi2(mod_data)
#LC_results <- chiM(mod_data)
LC_results <- extendChi2(mod_data)
LC_results$Disc.data
LC_results$cutp
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
#LC_results <- mdlp(mod_data)
#LC_results <- chi2(mod_data)
#LC_results <- chiM(mod_data)
LC_results <- modChi2(mod_data)
#LC_results <- extendChi2(mod_data)
LC_results$Disc.data
LC_results$cutp
# LC data
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
#LC_results <- mdlp(mod_data)
LC_1 <- chi2(mod_data[,1])
LC_2 <- chi2(mod_data[,2])
LC_3 <- chi2(mod_data[,3])
LC_results <- chi2(mod_data)
library('discretization')
# LC data
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
#LC_results <- mdlp(mod_data)
LC_1 <- chi2(mod_data[,1])
LC_2 <- chi2(mod_data[,2])
LC_3 <- chi2(mod_data[,3])
LC_results <- chi2(mod_data)
# LC data
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
#LC_results <- mdlp(mod_data)
LC_1 <- chi2(mod_data[,c(1,8)])
LC_2 <- chi2(mod_data[,c(2,8)])
LC_3 <- chi2(mod_data[,c(3,8)])
LC_results <- chi2(mod_data)
View(mod_data)
LC_1 <- chi2(mod_data[,c(1,7)])
LC_2 <- chi2(mod_data[,c(2,7)])
LC_3 <- chi2(mod_data[,c(3,7)])
# LC data
mydata = read.csv("C:\\Startup.ML\\lending\\data\\lc_data_2008.csv")
#target_class <- mydata$grade
#LC_data <- mydata[,c("dti")]
full_data <- mydata[,c("annual_inc","dti","earliest_cr_line","fico_range_low",
"fico_range_high","loan_amnt","delinq_2yrs","inq_last_6mths",
"collections_12_mths_ex_med","sub_grade")]
mod_data <- full_data
mod_data$fico_mean <- (mod_data$fico_range_low + mod_data$fico_range_high) * 0.5
mod_data$fico_range_low <- NULL
mod_data$fico_range_high <- NULL
mod_data <- mod_data[ ,c(1:7,9,8)]
mod_data$earliest_cr_line <- NULL
mod_data$collections_12_mths_ex_med <- NULL
#sort_data <- mod_data[order(mod_data$grade),]
LC_results <- mdlp(mod_data)
x1<-sample(c(-1.5, 2.5), 1000)
length(unique(x1)) #absolute number of different variables
length(unique(x1))/length(x1) #relative
x2<-runif(1000)
length(unique(x2)) #absolute number of different variables
length(unique(x2))/length(x2) #relative
x1<-sample(c(-1.5, 2.5), 1000)
length(unique(x1)) #absolute number of different variables
length(unique(x1))/length(x1) #relative
x2<-runif(1000)
length(unique(x2)) #absolute number of different variables
length(unique(x2))/length(x2) #relative
x1<-sample(c(-1.5, 2.5), 1000)
fipszips("CA")
fipszips("CA")
install.packages("zipcode")
install.packages("data.table")
fipszips("CA")
fipszips <- function( stateAbbrev = stateAbbrev ){
packages <- c("data.table", "zipcode") # List of libraries
runLib <- function(packages = packages) {
packagesCheck <- packages[!(packages %in% installed.packages()[,"Package"])]
if(length(packagesCheck)) {install.packages(packagesCheck)}; rm(packagesCheck)
lapply(packages, function(x) {do.call("require", list(x))})
}
runLib(packages)
stateAbbrev <- as.character(stateAbbrev)
library(zipcode); data(zipcode); head(zipcode)
library(data.table)
stateTable <- read.table(textConnection(
"stateAbbreviation  fips	state
AK	2	ALASKA
AL	1	ALABAMA
AR	5	ARKANSAS
AS	60	AMERIICAN SAMOA
AZ	4	ARIZONA
CA	6	CALIFORNIA
CO	8	COLORADO
CT	9	CONNECTICUT
DC	11	DISTRICT OF COLUMBIA
DE	10	DELAWARE
FL	12	FLORIDA
GA	13	GEORGIA
GU	66	GUAM
HI	15	HAWAII
IA	19	IOWA
ID	16	IDAHO
IL	17	ILLINOIS
IN	18	INDIANA
KS	20	KANSAS
KY	21	KENTUCKY
LA	22	LOUISIANA
MA	25	MASSACHUSETTS
MD	24	MARYLAND
ME	23	MAINE
MI	26	MICHIGAN
MN	27	MINNESOTA
MO	29	MISSOURI
MS	28	MISSISSIPPI
MT	30	MONTANA
NC	37	NORTH CAROLINA
ND	38	NORTH DAKOTA
NE	31	NEBRASKA
NH	33	NEW HAMPSHIRE
NJ	34	NEW JERSEY
NM	35	NEW MEXICO
NV	32	NEVADA
NY	36	NEW YORK
OH	39	OHIO
OK	40	OKLAHOMA
OR	41	OREGON
PA	42	PENNSYLVANIA
PR	72	PUERTO RICO
RI	44	RHODE ISLAND
SC	45	SOUTH CAROLINA
SD	46	SOUTH DAKOTA
TN	47	TENNESSEE
TX	48	TEXAS
UT	49	UTAH
VA	51	VIRGINIA
VI	78	VIRGIN ISLANDS
VT	50	VERMONT
WA	53	WASHINGTON
WI	55	WISCONSIN
WV	54	WEST VIRGINIA
WY	56	WYOMING")
, sep = "\t", header=T, stringsAsFactors = T)
stateTable <<- data.table(stateTable)
stateTable$stateAbbreviation <- as.character(gsub("[[:space:]]", "", stateTable$stateAbbreviation))
stateFipCode <- stateTable[ which(stateTable$stateAbbreviation==stateAbbrev), ][,"fips"]
stateFipsString <- sprintf("%02.0f", stateFipCode)
## County FIP and names data
# http://www2.census.gov/geo/docs/reference/codes/files/st06_ca_cou.txt
countyFips <- data.table(read.table(url(paste0("http://www2.census.gov/geo/docs/reference/codes/files/st",stateFipsString, "_",
tolower(stateAbbrev),"_cou.txt")), quote = "", sep = ",", header = F, stringsAsFactors = F)); closeAllConnections()
# Clean county data per state
setnames(countyFips, names(countyFips), c("stateAbbreviation", "stateFips", "countyFips", "county","incorpType"))
countyFips$county <- gsub(" County", "", countyFips$county)
# Clean stateTable
stateTableNarrow <<- stateTable[ which(stateTable$stateAbbreviation == stateAbbrev),]
stateTableNarrow <- data.table(stateTableNarrow)
setkeyv(countyFips, "stateAbbreviation")
setkeyv(stateTableNarrow, "stateAbbreviation")
fullTable <- merge(stateTableNarrow, countyFips, all = T, allow.cartesian=T)[,fips:=NULL]
## Community and Municipality FIPS data   /st",stateFipCode, "_",
# http://www2.census.gov/geo/docs/reference/codes/files/st06_ca_places.txt
placeFips <- data.table(read.table(url(paste0("http://www2.census.gov/geo/docs/reference/codes/files/st",stateFipsString, "_",
tolower(stateAbbrev),"_places.txt")), quote = "", sep = "|", header = F, stringsAsFactors = T)); closeAllConnections()
setnames(placeFips, names(placeFips), c("stateAbbreviation", "stateFips", "placeFips", "place","censusPlaceType","placeSym","county"))
placeFips <- placeFips[,stateFips:=NULL]
# gsub remove last word " CDP" | " city" | " town"
placeFips$place <- gsub(" town","", gsub(" CDP","", gsub(" city","",placeFips$place)))
# placeFips$place # gsub remove " County"
placeFips$county <- gsub(" County","",placeFips$county)
placeFips <-  placeFips[, stateAbbreviation:=NULL]
setkeyv(fullTable,"county")
setkeyv(placeFips, "county")
# options( datatable.print.topn = 30)
fullTable <- merge(fullTable, placeFips, all = T, allow.cartesian = T )
## Munge zipcode data
zipData <- zipcode[ which(zipcode$state==stateAbbrev), ]
names(zipData)[which( names(zipData) == "state")] <- "stateAbbreviation"
names(zipData)[which( names(zipData) == "city")] <- "place"
zipData <- data.table(zipData)
zipData <- zipData[,stateAbbreviation:=NULL]
setkeyv( zipData , "place" )
setkeyv( fullTable, "place" )
fullTable <- merge(fullTable, zipData , all = T , allow.cartesian = T)[,incorpType:=NULL]
# # NOTE: Replaces State Census NAs with matched values per state. Zip codes may cross state boundaries
# for(i in 1:length(fullTable$state)){
#   if(is.na(fullTable$state)[i]){
#     as.character(fullTable$state)[i] <- as.character(stateTableNarrow[,"state"])
#   }
# }
#
#
# for(i in 1:length(fullTable$stateFips)){
#   if(is.na(fullTable$stateFips)[i]){
#     as.integer(fullTable$stateFips)[i] <- as.integer(stateTableNarrow[,"fips"])
#   }
# }
#
# for(i in 1:length(fullTable$stateAbbreviation)){
#   if(is.na(fullTable$stateAbbreviation)[i]){
#     fullTable$stateAbbreviation[i] <- as.character(stateTableNarrow[,"stateAbbreviation"])
#   }
# }
fullTable <<- fullTable
censusPlaceTypes <<- table(placeFips$placeType)
censusPlaces <<- length(unique(placeFips$place))
uniqueZipPlaces <<- dim( zipcode[which(zipcode$state=="CA"),] )[1]
# fullTable[ which(fullTable$county=="Los Angeles"),]
uniqueCensusPlaces <<- unique(placeFips$place)
#Stats: Counties in State
countyCount <<- length(unique(countyFips$county))
cat("Census Places in", stateAbbrev, ":", censusPlaces, "\n" )
cat("Zip Places in", stateAbbrev,":", uniqueZipPlaces , "\n")
cat("Counties in", stateAbbrev,":", countyCount)
closeAllConnections()
}
fipszips("CA")
fipszips("WA")
# create variables to store the path to the files
setwd("C:/python_repo/sr_repo/kaggle_face_detect")
load('data.Rd')
colMeans(d.train, na.rm=T)
p <- matrix(data=colMeans(d.train, na.rm=T), nrow=nrow(d.test), ncol=ncol(d.train), byrow=T)
p
colnames(p) <- names(d.train)
predictions <- data.frame(ImageId = 1:nrow(d.test), p)
head(predictions)
# expected submission format has one one keypoint per row, but we can easily get that
# with the helpinstall.packages('reshape2')
library(reshape2)
submission <- melt(predictions, id.vars="ImageId", variable.name="FeatureName", value.name="Location")
head(submission)
# join this with the sample submission file to preserve the same order of entries and
# save the result
s <- paste0('Data/', 'SampleSubmission.csv')
example.submission <- read.csv(s)
sub.col.names      <- names(example.submission)
example.submission$Location <- NULL
submission <- merge(example.submission, submission, all.x=T, sort=F)
submission <- submission[, sub.col.names]
write.csv(submission, file="submission_means.csv", quote=F, row.names=F)
# parameters
coord      <- "left_eye_center"
patch_size <- 10
coord_x <- paste(coord, "x", sep="_")
coord_y <- paste(coord, "y", sep="_")
patches <- foreach (i = 1:nrow(d.train), .combine=rbind) %do% {
im  <- matrix(data = im.train[i,], nrow=96, ncol=96)
x   <- d.train[i, coord_x]
y   <- d.train[i, coord_y]
x1  <- (x-patch_size)
x2  <- (x+patch_size)
y1  <- (y-patch_size)
y2  <- (y+patch_size)
if ( (!is.na(x)) && (!is.na(y)) && (x1>=1) && (x2<=96) && (y1>=1) && (y2<=96) )
{
as.vector(im[x1:x2, y1:y2])
}
else
{
NULL
}
}
mean.patch <- matrix(data = colMeans(patches), nrow=2*patch_size+1, ncol=2*patch_size+1)
# windows alternative to 'doMC' library to do parallel computing
install.packages('doSNOW ')
install.packages('foreach')
library('doSNOW')
library('foreach')
cl <- makeCluster(2)
registerDoSNOW(cl)
coord_x <- paste(coord, "x", sep="_")
coord_y <- paste(coord, "y", sep="_")
patches <- foreach (i = 1:nrow(d.train), .combine=rbind) %do% {
im  <- matrix(data = im.train[i,], nrow=96, ncol=96)
x   <- d.train[i, coord_x]
y   <- d.train[i, coord_y]
x1  <- (x-patch_size)
x2  <- (x+patch_size)
y1  <- (y-patch_size)
y2  <- (y+patch_size)
if ( (!is.na(x)) && (!is.na(y)) && (x1>=1) && (x2<=96) && (y1>=1) && (y2<=96) )
{
as.vector(im[x1:x2, y1:y2])
}
else
{
NULL
}
}
mean.patch <- matrix(data = colMeans(patches), nrow=2*patch_size+1, ncol=2*patch_size+1)
# visualize the result with image
image(1:21, 1:21, mean.patch[21:1,21:1], col=gray((0:255)/255))
# define parameter
search_size <- 2
# search_size indicates how many pixels we are going to move in each direction when searching
# for the keypoint. We will center the search on the average keypoint location, and go
# search_size pixels in each direction
mean_x <- mean(d.train[, coord_x], na.rm=T)
mean_y <- mean(d.train[, coord_y], na.rm=T)
x1     <- as.integer(mean_x)-search_size
x2     <- as.integer(mean_x)+search_size
y1     <- as.integer(mean_y)-search_size
y2     <- as.integer(mean_y)+search_size
# In this particular case the search will be from (64,35) to (68,39).
# We can use expand.grid to build a data frame with all combinations of x's and y's:
params <- expand.grid(x = x1:x2, y = y1:y2)
params
# Given a test image we need to try all these combinations, and see which one best matches
# the average_patch. We will do that by taking patches of the test images around these points
# and measuring their correlation with the average_patch. Take the first test image as
# an example:
im <- matrix(data = im.test[1,], nrow=96, ncol=96)
r  <- foreach(j = 1:nrow(params), .combine=rbind) %dopar% {
x     <- params$x[j]
y     <- params$y[j]
p     <- im[(x-patch_size):(x+patch_size), (y-patch_size):(y+patch_size)]
score <- cor(as.vector(p), as.vector(mean.patch))
score <- ifelse(is.na(score), 0, score)
data.frame(x, y, score)
}
# Inside the for loop, given a coordinate we extract an image patch p and compare it
# to the average_patch with cor. The ifelse is necessary for the cases where all the image
# patch pixels have the same intensity, as in this case cor returns NA. The result will
# look like this:
r
#Now all we need to do is return the coordinate with the highest score:
best <- r[which.max(r$score), c("x", "y")]
best
